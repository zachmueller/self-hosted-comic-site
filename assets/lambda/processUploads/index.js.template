const { S3Client, GetObjectCommand, HeadObjectCommand, PutObjectCommand } = require('@aws-sdk/client-s3');
const { DynamoDBClient } = require('@aws-sdk/client-dynamodb');
const { DynamoDBDocumentClient, PutCommand } = require('@aws-sdk/lib-dynamodb');

// Initialize clients
const s3Client = new S3Client({ region: 'us-east-1' });
const ddbClient = new DynamoDBClient({});
const ddbDocClient = DynamoDBDocumentClient.from(ddbClient);

// Function to trigger invalidations of S3 cache
async function triggerCacheInvalidation(metadata) {
	console.log('Triggering cache invalidation for new upload:', metadata);

	const timestamp = Date.now();
	const invalidations = [];

	// Always invalidate the "all comics" cache
	invalidations.push(`invalidation/all/${timestamp}`);

	// Invalidate cache for each tag
	if (metadata.tags && metadata.tags.length > 0) {
		for (const tag of metadata.tags) {
			invalidations.push(`invalidation/tags/${tag}/${timestamp}`);
		}
	}

	// Create empty invalidation trigger files
	for (const key of invalidations) {
		try {
			await s3Client.send(new PutObjectCommand({
				Bucket: process.env.COMIC_BUCKET_NAME,
				Key: key,
				Body: '', // Empty file
				ContentLength: 0
			}));
			console.log(`Created invalidation trigger: ${key}`);
		} catch (error) {
			// Continue with other invalidations even if one fails
			console.error(`Error creating invalidation trigger for ${key}:`, error);
		}
	}
}

function validateMetadata(metadata) {
	const errors = [];

	// Required fields validation
	const requiredFields = ['id', 'title', 'slug', 'images'];
	requiredFields.forEach(field => {
		if (!metadata[field]) {
			errors.push(`Missing required field: ${field}`);
		}
	});

	// Images array validation
	if (metadata.images) {
		if (!Array.isArray(metadata.images)) {
			errors.push('images must be an array');
		} else {
			metadata.images.forEach((image, index) => {
				if (!image.key || typeof image.key !== 'string') {
					errors.push(`Image at index ${index} missing or invalid key`);
				}
				if (image.altText && typeof image.altText !== 'string') {
					errors.push(`Image at index ${index} has invalid altText type`);
				}
			});
		}
	}

	// String fields validation
	const stringFields = ['title', 'slug', 'caption', 'scrollStyle'];
	stringFields.forEach(field => {
		if (metadata[field] && typeof metadata[field] !== 'string') {
			errors.push(`${field} must be a string`);
		}
	});

	// Tags validation
	if (metadata.tags) {
		if (!Array.isArray(metadata.tags)) {
			errors.push('tags must be an array');
		} else if (metadata.tags.some(tag => typeof tag !== 'string')) {
			errors.push('all tags must be strings');
		}
	}

	// Date validations
	if (metadata.happenedOnDate) {
		const date = new Date(metadata.happenedOnDate);
		if (isNaN(date.getTime())) {
			errors.push('happenedOnDate must be a valid date');
		}
	}

	if (metadata.postedTimestamp) {
		const timestamp = new Date(metadata.postedTimestamp);
		if (isNaN(timestamp.getTime())) {
			errors.push('postedTimestamp must be a valid timestamp');
		}
	}

	// Integrations validation
	if (metadata.integrations) {
		if (!Array.isArray(metadata.integrations)) {
			errors.push('integrations must be an array');
		} else {
			metadata.integrations.forEach((integration, index) => {
				if (!integration.type || typeof integration.type !== 'string') {
					errors.push(`Integration at index ${index} missing or invalid type`);
				}
				if (typeof integration.use !== 'boolean') {
					errors.push(`Integration at index ${index} missing or invalid use flag`);
				}
			});
		}
	}

	// If any errors were found, throw them
	if (errors.length > 0) {
		throw new Error('Metadata validation failed:\n' + errors.join('\n'));
	}

	return true;
}

exports.handler = async (event) => {
    const bucket = event.Records[0].s3.bucket.name;
    const key = decodeURIComponent(event.Records[0].s3.object.key);
    try {
        // Get metadata file
        const metadataResponse = await s3Client.send(new GetObjectCommand({
            Bucket: bucket,
            Key: key,
        }));

        if (!metadataResponse.Body) {
            throw new Error('No metadata body received');
        }

        const metadata = JSON.parse(await streamToString(metadataResponse.Body));

		// Validate the metadata structure
		validateMetadata(metadata);

		// Prepare item for DynamoDB
		const itemToWrite = {
			...metadata,
			uploadDate: new Date().toISOString(),
		};

		// Convert tags to DynamoDB Set if present
		if (metadata.tags && Array.isArray(metadata.tags)) {
			itemToWrite.tags = new Set(metadata.tags);
		}

		// Write to DynamoDB
		await ddbDocClient.send(new PutCommand({
			TableName: process.env.COMIC_TABLE_NAME,
			Item: itemToWrite
		}));

		// Refresh the S3 cache to include new comics
		await triggerCacheInvalidation(metadata);

        return {
            statusCode: 200,
            body: JSON.stringify({
                message: 'Successfully processed metadata',
                slug: metadata.slug
            })
        };
    } catch (error) {
        console.error('Error processing metadata:', error);
        throw error;
    }
};

// Utility function to convert stream to string
async function streamToString(stream) {
    return new Promise((resolve, reject) => {
        const chunks = [];
        stream.on('data', (chunk) => chunks.push(chunk));
        stream.on('error', reject);
        stream.on('end', () => resolve(Buffer.concat(chunks).toString('utf8')));
    });
}